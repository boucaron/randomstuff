Superintelligence: Paths, Dangers, Strategies by Nick Bostrom

I had a first initial quick read and I was not in the mood.
I mean that I was not concentrated enough to really dive into and start to appreciate it.
So far, I consummed a few chapters, I am still skeptical at the current time (2022), but not strongly skeptical.
As introduction, there is a short introduction to IA and a quick history.
Then, it talks about various kind of improvements in various fields biological, chips, simulation, algorithms ...etc...
The current limits of the state of the art back to 2015 are well explained.
I agree there is really something about various "compounding" effects which makes sense when you know the exponential improvements in the chips.
Weak AI is already a reality in more and more fields: it can be stupid (or even more stupid) than a human and also very dangerous.
For Strong AI I do not know, I think the main issue is 'algorithmic': it is a man made. There is also an hardware issue which is less important overtime, will we have stagnation on this side, possibly. Of course it is just a feeling, there are complex interaction and feedback loops that will improve and it will provide speed-up increments, but is it an exponential speed-up, outside of the hardware part, I don't know.
Strong IA is a problem with combinatorial explosion in several dimensions, even thousands or higher order of magnitude on the hardware are still just few atoms in a problem of the size of the universe, it will not change too much with a better hardware something you cannot solve in your lifetime: so the 'algorithmic' issue for the moment is the human problem.
Of course existing Weak IA can help to accelerate super clever humans to tackle the Strong IA problem and most of the time will improve or create better Weaker IA. However, does such Weak IA provides to the human an improved intelligence, up to a point yes, but is it enough to the Strong IA problem, I am not sure.
For instance, we have easy access to a huge amount of information that was not possible few decades ago, we can know more than all of our ancestors together but are we really more intelligent, it is not so obvious. Let say we have external Weak IA accelerators to further improve our slow biological brain, even so will we be able to reach the intelligence plateau required to solve the 'algorithm' issue to the Strong IA, for sure it will be faster but will it be enough ?




